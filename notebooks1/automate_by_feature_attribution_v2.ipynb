{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9f0ede-26dd-4990-8017-8d477870e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from sae.sparse_autoencoder import load_saved_sae\n",
    "from sae.metrics import model_store_from_sae\n",
    "from unlearning.metrics import convert_wmdp_data_to_prompt, convert_list_of_dicts_to_dict_of_lists\n",
    "from unlearning.tool import UnlearningConfig, SAEUnlearningTool, MCQ_ActivationStoreAnalysis, ActivationStoreAnalysis\n",
    "from unlearning.metrics import modify_and_calculate_metrics, calculate_metrics_list, create_df_from_metrics\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from transformer_lens import utils\n",
    "\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "import einops\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "from unlearning.var import REPO_ID, SAE_MAPPING\n",
    "import pickle\n",
    "\n",
    "from unlearning.metrics import all_permutations\n",
    "\n",
    "from unlearning.feature_attribution import find_topk_features_given_prompt, test_topk_features\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858edeed-c102-46e4-aa6b-fbdd246ecd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92331e8f4d948f0ba5d43fd889cf822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(â€¦)cks.9.hook_resid_pre_s16384_127995904.pt:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ba429220274e2a89d51b6a11fc782f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54281f82afcd49ad976ec86e88357fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50699bd5317f40f993c7e9bc7829c605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b427cfa66224b50a119840b11c77213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390ad22a752a48979fbf55e0a0f35ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8e7c5be14e468481e0e3443dd96472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9912a46df34bd1bf5eeae64ccb2f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54d1545bc4f496b936a33e1a6b84477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18e6e91e4674d47a0398a9d4bebf943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea28a762b0b4f80883c01c739e97762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86dc3e117be4c3682bb9ed8e62a354e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b-it into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# Load main SAE for gemma-2b-it\n",
    "filename = hf_hub_download(repo_id=REPO_ID, filename=SAE_MAPPING['gemma_2b_it_resid_pre_9'])\n",
    "sae = load_saved_sae(filename)\n",
    "model = model_store_from_sae(sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e86fcff-2807-48b8-b224-c984e3463b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ab94ff0eb84aa6af635ee36fe13e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/4.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94f71bc1240405e808056483de468c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/258k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d6dcb562094365808aa5475572e5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1273 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pass in the dataset as an argument so no need to load in everytime\n",
    "dataset = load_dataset(\"cais/wmdp\", \"wmdp-bio\")\n",
    "\n",
    "answers = [x['answer'] for x in dataset['test']]\n",
    "questions = [x['question'] for x in dataset['test']]\n",
    "choices_list = [x['choices'] for x in dataset['test']]\n",
    "\n",
    "prompts = [convert_wmdp_data_to_prompt(question, choices, prompt_format=None) for question, choices in zip(questions, choices_list)]\n",
    "\n",
    "# features_ids_prompt_70 = [ 5681, 12639,  9597,  6272, 14509]\n",
    "\n",
    "unlearning_dataset = ['wmdp-bio']\n",
    "side_effect_dataset_names =  ['high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging', 'college_biology']\n",
    "all_dataset_names = ['loss_added', 'wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging', 'college_biology']\n",
    "\n",
    "question_ids_correct = np.genfromtxt(\"../data/wmdp-bio_gemma_2b_it_correct_no_tricks.csv\")\n",
    "\n",
    "non_zero_features_list = np.genfromtxt(\"non_zero_features_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "063cfc3f-c632-4435-829a-9a712e76e56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question # 1147 1 /159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:13<00:00,  1.46s/it]\n"
     ]
    }
   ],
   "source": [
    "question_ids = [357, 1147]\n",
    "\n",
    "feature_per_prompt = {}\n",
    "\n",
    "known_good_features = []\n",
    "\n",
    "model.reset_hooks()\n",
    "\n",
    "question_ids_correct[:1]\n",
    "\n",
    "for j, question_id in enumerate([1147]):\n",
    "\n",
    "    question_id = int(question_id)\n",
    "\n",
    "    print(\"Question #\", question_id, j+1, \"/159\")\n",
    "    \n",
    "    prompt = prompts[question_id]\n",
    "    choices = choices_list[question_id]\n",
    "    answer = answers[question_id]\n",
    "    question = questions[question_id]\n",
    "\n",
    "    topk_features_unique = find_topk_features_given_prompt(model,\n",
    "                                                           prompt,\n",
    "                                                           question,\n",
    "                                                           choices,\n",
    "                                                           answer,\n",
    "                                                           sae,\n",
    "                                                           hook_point='blocks.9.hook_resid_pre')[0]\n",
    "    \n",
    "    intervention_results, feature_ids_to_probs, good_features = test_topk_features(model,\n",
    "                                                                                   sae,\n",
    "                                                                                   question_id,\n",
    "                                                                                   topk_features_unique[:50],\n",
    "                                                                                   known_good_features=known_good_features,\n",
    "                                                                                   multiplier=30,\n",
    "                                                                                   thres_correct_ans_prob=0.8,\n",
    "                                                                                   permutations=all_permutations)\n",
    "\n",
    "    feature_per_prompt[question_id] = good_features\n",
    "    \n",
    "    known_good_features = list(set([item for sublist in feature_per_prompt.values() for item in sublist]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "45647e23-6cce-4dbd-bcca-094a8ec3b41e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{22: [12359,\n",
       "  4802,\n",
       "  8794,\n",
       "  10632,\n",
       "  6308,\n",
       "  4997,\n",
       "  12782,\n",
       "  12663,\n",
       "  2993,\n",
       "  12435,\n",
       "  15755,\n",
       "  5904]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_per_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e854eabb-d530-484c-98cc-6eb862d9fdfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1147: [4802, 8139, 12289, 12273, 13715, 4550, 9280, 5904, 10189]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_per_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9a5ea-5abe-4561-94c5-17a6b69bffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "\n",
    "main_ablate_params = {\n",
    "                      'multiplier': 20,\n",
    "                      'intervention_method': 'clamp_feature_activation',\n",
    "                     }\n",
    "\n",
    "\n",
    "sweep = {\n",
    "         'features_to_ablate': features_for_prompt_243,\n",
    "        }\n",
    "\n",
    "metric_params = {'wmdp-bio': \n",
    "                 {\n",
    "                       'target_metric': 'correct',\n",
    "                       'permutations': None,\n",
    "                   }\n",
    "                 }\n",
    "\n",
    "dataset_names = all_dataset_names[2:]\n",
    "\n",
    "n_batch_loss_added = 10\n",
    "\n",
    "metrics_list = calculate_metrics_side_effects(model,\n",
    "                                      sae,\n",
    "                                      main_ablate_params,\n",
    "                                      sweep,\n",
    "                                      dataset_names=dataset_names,\n",
    "                                      metric_params=metric_params,\n",
    "                                      n_batch_loss_added=n_batch_loss_added,)\n",
    "                                      # activation_store=activation_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd5fb21-6380-4b9d-b35c-ee06372c3ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question # 22 1 /159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:13,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question # 351 21 /159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:26,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question # 447 41 /159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:44,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question # 630 61 /159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [01:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question # 735 81 /159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [01:19,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question # 826 101 /159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [01:38,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question # 933 121 /159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [01:58,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question # 1130 141 /159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159it [02:14,  1.18it/s]\n"
     ]
    }
   ],
   "source": [
    "## Find all non-zero features\n",
    "feature_per_prompt = {}\n",
    "\n",
    "known_good_features = []\n",
    "\n",
    "model.reset_hooks()\n",
    "\n",
    "non_zero_features_list = []\n",
    "\n",
    "for j, question_id in tqdm(enumerate(question_ids_correct)):\n",
    "\n",
    "    question_id = int(question_id)\n",
    "\n",
    "    if j % 20 == 0:\n",
    "        print(\"Question #\", question_id, j+1, \"/159\")\n",
    "    \n",
    "    prompt = prompts[question_id]\n",
    "    choices = choices_list[question_id]\n",
    "    answer = answers[question_id]\n",
    "    question = questions[question_id]\n",
    "\n",
    "    all_feature_attributions = find_topk_features_given_prompt(model,\n",
    "                                                           prompt,\n",
    "                                                           question,\n",
    "                                                           choices,\n",
    "                                                           answer,\n",
    "                                                           sae,\n",
    "                                                           hook_point='blocks.9.hook_resid_pre')[1]\n",
    "    non_zero_features = list(all_feature_attributions.min(axis=0)[0].nonzero().T[0].cpu().numpy())\n",
    "    non_zero_features_list.append(non_zero_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1b422c-53f5-468c-b98d-77d63da985b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_zero_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfa64935-bd4e-4764-b7a8-32e9d03098f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279.0377358490566"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(x) for x in non_zero_features_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b35c839-5f56-4cb7-872f-a50fd7cffc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_zero_features_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "808ab6c0-9072-4224-95c3-5cc400ca8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_non_zero_features = [item for sublist in non_zero_features_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a8933e5-9571-4427-9565-00887ecade2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 s, sys: 0 ns, total: 18.2 s\n",
      "Wall time: 18.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features_to_prompts = {}\n",
    "\n",
    "for f in all_non_zero_features:\n",
    "    prompts = [prompt for prompt, features in zip(question_ids_correct, non_zero_features_list) if f in features]\n",
    "    features_to_prompts[f] = prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4bc9b41-b1ea-4cb1-b027-d06432398b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22.0, 158.0, 559.0, 744.0, 958.0, 1116.0, 1165.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_prompts[57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83c5954-1168-428a-844d-186e36767b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9598e345-a7fd-4f53-9274-d93efb0847c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_features_list2 = [item for sublist in non_zero_features_list for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0db6ebb6-6466-4131-bf27-09a65666ccbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  6, 12, 13, 15, 17, 18, 19, 20, 25, 26, 28, 29, 32, 33,\n",
       "       37, 41, 42])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(non_zero_features_list)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d233eb5c-3673-41e4-998c-adfeae1facba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5592045c-7768-4fed-8838-eff6fef8ef2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6378"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(non_zero_features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4e96dad1-8c19-40d7-8140-6090dfb17733",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"non_zero_features_list.csv\", np.unique(non_zero_features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b23513c6-dd1c-4978-acb0-4800eb189bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d2adb7-8193-4b86-93c4-802ccd1debc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0000e+00, 2.0000e+00, 3.0000e+00, ..., 1.6381e+04, 1.6382e+04,\n",
       "       1.6383e+04])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90478569-2ced-4fe2-8df3-3bfb2092f435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6378"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_zero_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6579503f-ce50-430e-a321-50ec014ea382",
   "metadata": {},
   "source": [
    "## Unlearn permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81405eb2-b499-4db2-87b1-36f223cafcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7879c2c1-75f4-4e07-9e5b-5b2712c102e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features_to_prompts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features_to_prompts' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "for f in tqdm(list(features_to_prompts.keys())[:100]):\n",
    "             \n",
    "    ablate_params = {\n",
    "                      'multiplier': 30,\n",
    "                      'intervention_method': 'clamp_feature_activation',\n",
    "                      'features_to_ablate': [int(f)]\n",
    "                     }\n",
    "    \n",
    "                 \n",
    "    metric_params = {'wmdp-bio': \n",
    "                     {\n",
    "                           'question_subset': [int(x) for x in features_to_prompts[f]],\n",
    "                           'permutations': None,\n",
    "                           'verbose': False,\n",
    "                       }\n",
    "                     }\n",
    "\n",
    "    print([int(x) for x in features_to_prompts[f]])\n",
    "    \n",
    "    \n",
    "    metrics = modify_and_calculate_metrics(model,\n",
    "                                     sae,\n",
    "                                     dataset_names=['wmdp-bio'],\n",
    "                                     metric_params=metric_params,\n",
    "                                     activation_store=None,\n",
    "                                     **ablate_params)\n",
    "\n",
    "    all_metrics.append(metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5d199-7eed-4d4f-9944-6da76f1dcfb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f67c4-84e2-44cb-8555-50e932787bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519ed227-c885-420b-8d2a-0754257eeec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [02:54<4:47:12, 174.07s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:22\u001b[0m\n",
      "File \u001b[0;32m/notebooks/unlearning/eoin_notebooks/../unlearning/metrics.py:861\u001b[0m, in \u001b[0;36mcalculate_metrics_list\u001b[0;34m(model, sae, main_ablate_params, sweep, dataset_names, metric_params, include_baseline_metrics, n_batch_loss_added, activation_store)\u001b[0m\n\u001b[1;32m    856\u001b[0m ablate_params_list \u001b[38;5;241m=\u001b[39m generate_ablate_params_list(main_ablate_params, sweep)\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ablate_params \u001b[38;5;129;01min\u001b[39;00m tqdm(ablate_params_list):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# print(j, ablate_params)\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m     ablated_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mmodify_and_calculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msae\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdataset_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmetric_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mn_batch_loss_added\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_batch_loss_added\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mactivation_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactivation_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mablate_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m     metrics_list\u001b[38;5;241m.\u001b[39mappend(ablated_metrics)\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# print()\u001b[39;00m\n",
      "File \u001b[0;32m/notebooks/unlearning/eoin_notebooks/../unlearning/metrics.py:792\u001b[0m, in \u001b[0;36mmodify_and_calculate_metrics\u001b[0;34m(model, sae, dataset_names, metric_params, n_batch_loss_added, activation_store, **ablate_params)\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m         metric_param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_metric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcorrect\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[0;32m--> 792\u001b[0m     dataset_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_MCQ_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m     metrics_for_current_ablation[dataset_name] \u001b[38;5;241m=\u001b[39m dataset_metrics\n\u001b[1;32m    797\u001b[0m model\u001b[38;5;241m.\u001b[39mreset_hooks()\n",
      "File \u001b[0;32m/notebooks/unlearning/eoin_notebooks/../unlearning/metrics.py:134\u001b[0m, in \u001b[0;36mcalculate_MCQ_metrics\u001b[0;34m(model, dataset_name, target_metric, question_subset, question_subset_file, permutations, verbose, without_question, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     n_batches \u001b[38;5;241m=\u001b[39m n_batches \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# print(n_batches)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m output_probs \u001b[38;5;241m=\u001b[39m \u001b[43mget_output_probs_abcd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m predicted_answers \u001b[38;5;241m=\u001b[39m output_probs\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    137\u001b[0m predicted_probs \u001b[38;5;241m=\u001b[39m output_probs\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/notebooks/unlearning/eoin_notebooks/../unlearning/metrics.py:257\u001b[0m, in \u001b[0;36mget_output_probs_abcd\u001b[0;34m(model, prompts, batch_size, n_batches, verbose)\u001b[0m\n\u001b[1;32m    255\u001b[0m vals \u001b[38;5;241m=\u001b[39m model(token_batch, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    256\u001b[0m t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 257\u001b[0m vals \u001b[38;5;241m=\u001b[39m vals[\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, next_token_indices]\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# vals = torch.vstack([x[i] for x, i in zip(vals, next_token_indices)]).softmax(-1)\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# vals = vals[0, -1].softmax(-1)\u001b[39;00m\n\u001b[1;32m    260\u001b[0m t2 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "main_ablate_params = {\n",
    "                      'multiplier': 30,\n",
    "                      'intervention_method': 'clamp_feature_activation',\n",
    "                     }\n",
    "\n",
    "sweep = {\n",
    "         'features_to_ablate': [int(x) for x in non_zero_features_list[:100]],\n",
    "        }\n",
    "\n",
    "metric_params = {'wmdp-bio': \n",
    "                 {\n",
    "                       'question_subset': question_ids_correct,\n",
    "                       'permutations': all_permutations,\n",
    "                       'verbose': False,\n",
    "                   }\n",
    "                 }\n",
    "\n",
    "dataset_names = all_dataset_names[1:2]\n",
    "\n",
    "n_batch_loss_added = 50\n",
    "\n",
    "metrics = calculate_metrics_list(model,\n",
    "                                  sae,\n",
    "                                  main_ablate_params,\n",
    "                                  sweep,\n",
    "                                  dataset_names=dataset_names,\n",
    "                                  metric_params=metric_params,\n",
    "                                  n_batch_loss_added=n_batch_loss_added,)\n",
    "                                  # activation_store=activation_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de657fe7-acca-4ded-9671-67d8b49a6d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b0fc912-957a-4737-b069-37363a37c2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999403953552"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[0]['wmdp-bio']['mean_correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6561b081-30e1-4b60-862f-c898d4a3bc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_correct = [int(round(x['wmdp-bio']['mean_correct'] * 24 * 159, 0)) for x in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca3e2546-415d-433f-8c95-3c0cd146f626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3768, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3792, 3816, 3792, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3792, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3792, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3744, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3792, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3816, 3816, 3816, 3768, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816, 3816, 3792, 3816, 3792, 3816, 3816, 3816, 3816, 3816,\n",
       "       3816, 3816])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(mean_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "057925ff-cd26-444f-a08a-defdf878ac10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(mean_correct) < 3816).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67e95d86-c9a4-4c2b-ad05-9eacaf1aad76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6378"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_zero_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f0c28fc-ad86-4911-b22a-a3a518526f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318.90000000000003"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6378 * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93c06d-f162-476c-9ac2-8ab76c2648e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c8c14-883d-4657-8a16-178b15632bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc66d27-e9a2-4a71-ac28-9415b3091b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c89296-d40a-4947-afff-903a9ef4ed52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a3690cb-e82b-4411-bf0c-a971d42edfc1",
   "metadata": {},
   "source": [
    "## Side Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "786a2f63-5c19-41ab-a300-ceccb27192ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# features_ids_prompt_70 = [ 5681, 12639,  9597,  6272, 14509]\n",
    "unlearning_dataset = ['wmdp-bio']\n",
    "side_effect_dataset_names =  ['high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging', 'college_biology']\n",
    "all_dataset_names = ['loss_added', 'wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging', 'college_biology']\n",
    "\n",
    "from unlearning.metrics import calculate_metrics_side_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77d1f9f3-95d4-42d8-a403-632bcb7fe9df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f822062492864bd184c06ea24c609b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/53.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c424b91e0f3409dbc785083da23158b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/138k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45833646a7847459fe8e21447e18c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/155k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f6980af3a5459daa5336db79bbefc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/27.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7997649d00d94fdf995be14b9c4e4d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/17.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08231265d4ac4e539a0c5812948a799f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/204 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d1218129ae43019247c64b7dfabd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3168390a4ab140328d4c23749cb64494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0b95c3739049308d2fb5cb1092e626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3594ae6f05b44c0b8900c70142241bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbd44d8c8d740afaeda940a36ecee09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4e2031e69d4c26bad6fe579ac6fc7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ce13cbd1e246b7a4faaddf41b0b7e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac4317e4e124f358924d2917f763b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43fc6715dcb4eeba26b1ca32e93f6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/28.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddea1090428e4f67b1aae21db45a4c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5c87d6c40740e086e115fe5ccb2119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17209d6fbc1a46e898a3a9d3aef30e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/198 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0df060d4a1947fe882cac09c62fb4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7edee36d0c4db69971c3535cdc5b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc87fa7b18147109eec202aa6ab147d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/31.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c320a1d4e8e4f2983dd9498eabd1ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8bf13877c9419eabd9ab6214f9bacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2c6afafa864d6b909f8be17bc54d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/223 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77561c915ff049ff8fb009cc121454bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/23 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6ba57db31049a8a3c4cbef77cee1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5ebef9cee24e5ba3d0229f10bc51fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/31.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381161652aae4435a88e15af2048733b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/6.90k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddf43fecbfd4b20841782e5f240c2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbd12f1b03f4570b8c82953c31f228e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/144 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9f1f1f1cec4f40a1ae82508c185db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05d077a46dd428795172a427cc15ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [03:53<00:00, 11.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "\n",
    "main_ablate_params = {\n",
    "                      'multiplier': 20,\n",
    "                      'intervention_method': 'clamp_feature_activation',\n",
    "                     }\n",
    "\n",
    "\n",
    "sweep = {\n",
    "         'features_to_ablate': [int(x) for x in non_zero_features_list[:20]],\n",
    "        }\n",
    "\n",
    "metric_params = {'wmdp-bio': \n",
    "                 {\n",
    "                       'target_metric': 'correct',\n",
    "                       'permutations': None,\n",
    "                   }\n",
    "                 }\n",
    "\n",
    "dataset_names = all_dataset_names[2:]\n",
    "\n",
    "n_batch_loss_added = 10\n",
    "\n",
    "metrics_list = calculate_metrics_side_effects(model,\n",
    "                                      sae,\n",
    "                                      main_ablate_params,\n",
    "                                      sweep,\n",
    "                                      dataset_names=dataset_names,\n",
    "                                      metric_params=metric_params,\n",
    "                                      n_batch_loss_added=n_batch_loss_added,)\n",
    "                                      # activation_store=activation_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8933056-3780-4d2a-a602-81d0ccef4646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  3,  6, 12, 13, 15, 17, 18, 19, 20, 25, 26, 28, 29, 32, 33,\n",
       "       37, 41, 42])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_ids_zero_side_effect = [x['ablate_params']['features_to_ablate'] for x in metrics_list]\n",
    "np.array(feature_ids_zero_side_effect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f0ad23c-eb1f-4f1c-b369-16b3187dd435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_ids_zero_side_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8953c9c2-ab58-41c5-a08a-228fb930aca1",
   "metadata": {},
   "source": [
    "## All feature activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bcac4bc-7775-4654-9771-a8671b2a91e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Dataset.__del__ at 0x7f0c2cacb920>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\", line 1421, in __del__\n",
      "    def __del__(self):\n",
      "\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"../data/wmdp-bio_gemma_2b_it_correct.csv\"\n",
    "correct_question_ids = np.genfromtxt(filename)\n",
    "\n",
    "dataset_args = {\n",
    "    'question_subset': correct_question_ids,\n",
    "}\n",
    "\n",
    "sae.cfg.n_batches_in_store_buffer = 86\n",
    "\n",
    "act_store = MCQ_ActivationStoreAnalysis(sae.cfg, model, dataset_args=dataset_args)\n",
    "unlearning_metric = 'wmdp-bio_gemma_2b_it_correct'\n",
    "\n",
    "unlearn_cfg = UnlearningConfig(unlearn_activation_store=act_store, unlearning_metric=unlearning_metric)\n",
    "ul_tool2 = SAEUnlearningTool(unlearn_cfg)\n",
    "ul_tool2.setup(model=model)\n",
    "ul_tool2.get_metrics_with_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d196cb-83fa-46ab-aca6-451d492b938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_with_text = ul_tool2.unlearn_metrics_with_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83a25d-b57c-4b4f-afcf-5fe9aefc2577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03babfaa-1f30-4a1f-82bc-61c79613a13a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
