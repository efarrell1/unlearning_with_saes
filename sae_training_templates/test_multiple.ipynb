{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38763708-17f0-44bd-901d-9bf84ebe5b7c",
   "metadata": {},
   "source": [
    "### Runs multiple models simulteously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672c63f4-7164-44dd-9427-80a7fa1cccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from sae.train import ModelTrainer, MultipleModelTrainer\n",
    "from sae.config import Config, generate_cfg_list\n",
    "import itertools\n",
    "from dataclasses import dataclass, asdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5f6989a-2c74-4f0d-9767-e00b6aa15be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_inputs = {\n",
    "    # Model and Hook Point\n",
    "    'model_name': 'gpt2-small',\n",
    "    'hook_point': 'blocks.1.hook_resid_pre',\n",
    "    'hook_point_layer': 1,\n",
    "    'hook_point_head_index': None,\n",
    "    'd_in': 768,\n",
    "\n",
    "    # Dataset\n",
    "    'dataset_path': 'Skylion007/openwebtext',\n",
    "    'is_dataset_tokenized': False,\n",
    "    \n",
    "     # Activation Store Parameters\n",
    "    'n_batches_in_store_buffer': 64,\n",
    "    'store_batch_size': 8,\n",
    "    'train_batch_size': 4096,\n",
    "    'context_size': 128,\n",
    "\n",
    "    # Outputs\n",
    "    'log_to_wandb': True,\n",
    "    'wandb_project': 'test_multiple',\n",
    "    'wandb_log_frequency': 10,\n",
    "    'eval_frequency': 500,\n",
    "    'sparsity_log_frequency': 5000,\n",
    "    'n_checkpoints': 5,\n",
    "    'checkpoint_path': '../outputs/checkpoints',\n",
    "\n",
    "    # Sparse Autoencoder Parameters\n",
    "    'expansion_factor': 32,\n",
    "    'normalise_w_dec': True,\n",
    "    'clip_grad_norm': False,\n",
    "    'scale_input_norm': False,\n",
    "\n",
    "    # General\n",
    "    'seed': 42,\n",
    "    'total_training_steps': 200000,\n",
    "\n",
    "    # Learning rate parameters\n",
    "    'lr': 0.0004,\n",
    "    'lr_scheduler_name': 'constant',\n",
    "\n",
    "    # Loss Function\n",
    "    'mse_loss_coefficient': 1,\n",
    "    'mse_loss_type': 'centered',\n",
    "    'l0_coefficient': 7e-5,\n",
    "    'epsilon_l0_approx': 0.2,\n",
    "    \n",
    "    'sparse_loss_coefficient': 1e-6,\n",
    "    'min_sparsity_target': 1e-5,\n",
    "\n",
    "}\n",
    "\n",
    "sweep = {'l0_coefficient': [3e-5, 5e-5, 7e-5, 9e-5]}\n",
    "\n",
    "cfg_list = generate_cfg_list(config_inputs, sweep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09cc1cbc-7349-42a3-bf57-73a463fc7893",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = MultipleModelTrainer(cfg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5937d0a7-74a6-4e57-880f-52410c4c4b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "creating activation store\n",
      "creating data loader\n",
      "buffer\n",
      "dataloader\n",
      "creating activation store\n",
      "creating sae\n",
      "creating wanbd\n",
      "creating activation store\n",
      "creating sae\n",
      "creating wanbd\n",
      "creating activation store\n",
      "creating sae\n",
      "creating wanbd\n",
      "creating activation store\n",
      "creating sae\n",
      "creating wanbd\n",
      "creating wanbd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meoin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/sparse_autoencoder/notebook_templates/wandb/run-20240508_125802-p6azadx4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eoin/test_multiple/runs/p6azadx4' target=\"_blank\">unique-glitter-13</a></strong> to <a href='https://wandb.ai/eoin/test_multiple' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eoin/test_multiple' target=\"_blank\">https://wandb.ai/eoin/test_multiple</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eoin/test_multiple/runs/p6azadx4' target=\"_blank\">https://wandb.ai/eoin/test_multiple/runs/p6azadx4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5b754-f80f-4bdd-9ec2-87508a817eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43dfab53ff6a49ba93742b474a5bf299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05e69a-78a7-497f-a298-e41f52a31f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fedbbe-0c4d-4548-96c5-78468fa3735d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
