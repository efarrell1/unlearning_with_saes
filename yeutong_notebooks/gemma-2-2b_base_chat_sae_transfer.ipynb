{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from unlearning.tool import get_hf_model\n",
    "from unlearning.feature_activation import get_forget_retain_data, tokenize_dataset, get_feature_activation_sparsity, get_top_features\n",
    "from unlearning.jump_relu import load_gemma2_2b_sae\n",
    "from unlearning.intervention import scaling_intervention\n",
    "from unlearning.metrics import calculate_MCQ_metrics, get_loss_added_hf, create_df_from_metrics, generate_ablate_params_list\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19520b98988c4a55ba36103b7bef011a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b-it into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be563d0e62d046d2b51b66e3d1cbaed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained('google/gemma-2-2b-it')\n",
    "base_model = HookedTransformer.from_pretrained('google/gemma-2-2b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found SAE with l0=59 at path google/gemma-scope-2b-pt-res/layer_3/width_16k/average_l0_59/params.npz\n"
     ]
    }
   ],
   "source": [
    "layer = 3\n",
    "sae = load_gemma2_2b_sae(layer=layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae.activation_store import ActivationsStore\n",
    "\n",
    "sae.cfg.dataset = \"Skylion007/openwebtext\"\n",
    "sae.cfg.n_batches_in_store_buffer = 8\n",
    "\n",
    "activation_store = ActivationsStore(sae.cfg, model, create_dataloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1257) tensor(3.2397)\n"
     ]
    }
   ],
   "source": [
    "activation_store.iterable_dataset = iter(activation_store.dataset)            \n",
    "\n",
    "n_batches = 100\n",
    "sae_losses = torch.zeros(n_batches)\n",
    "ori_losses = torch.zeros(n_batches)\n",
    "\n",
    "for i in range(n_batches):\n",
    "    tokens = activation_store.get_batch_tokenized_data()\n",
    "    sae_loss, ori_loss = sae.get_test_loss(tokens, model)\n",
    "    sae_losses[i] = sae_loss\n",
    "    ori_losses[i] = ori_loss\n",
    "    \n",
    "print(sae_losses.mean(), ori_losses.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_model_results = (sae_losses.mean(), ori_losses.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8860)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it_model_results[0] - it_model_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.8411) tensor(2.9781)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "activation_store.iterable_dataset = iter(activation_store.dataset)            \n",
    "\n",
    "n_batches = 100\n",
    "sae_losses = torch.zeros(n_batches)\n",
    "ori_losses = torch.zeros(n_batches)\n",
    "\n",
    "for i in range(n_batches):\n",
    "    tokens = activation_store.get_batch_tokenized_data()\n",
    "    sae_loss, ori_loss = sae.get_test_loss(tokens, base_model)\n",
    "    sae_losses[i] = sae_loss\n",
    "    ori_losses[i] = ori_loss\n",
    "    \n",
    "print(sae_losses.mean(), ori_losses.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8631)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_losses.mean() - ori_losses.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
