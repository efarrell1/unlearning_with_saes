{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from sae.sparse_autoencoder import load_saved_sae\n",
    "from sae.metrics import model_store_from_sae\n",
    "from unlearning.metrics import convert_wmdp_data_to_prompt, convert_list_of_dicts_to_dict_of_lists\n",
    "from unlearning.tool import UnlearningConfig, SAEUnlearningTool, MCQ_ActivationStoreAnalysis, ActivationStoreAnalysis\n",
    "from unlearning.metrics import modify_and_calculate_metrics, calculate_metrics_list, create_df_from_metrics\n",
    "from unlearning.feature_attribution import calculate_cache\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from transformer_lens import utils\n",
    "\n",
    "from jaxtyping import Float\n",
    "from torch import Tensor\n",
    "\n",
    "import einops\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import plotly.express as px\n",
    "from unlearning.var import REPO_ID, SAE_MAPPING\n",
    "import pickle\n",
    "\n",
    "from unlearning.metrics import all_permutations\n",
    "\n",
    "from unlearning.metrics import calculate_metrics_side_effects\n",
    "from unlearning.feature_attribution import find_topk_features_given_prompt, test_topk_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main SAE for gemma-2b-it\n",
    "filename = hf_hub_download(repo_id=REPO_ID, filename=SAE_MAPPING['gemma_2b_it_resid_pre_9'])\n",
    "sae = load_saved_sae(filename)\n",
    "model = model_store_from_sae(sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in the dataset as an argument so no need to load in everytime\n",
    "dataset = load_dataset(\"cais/wmdp\", \"wmdp-bio\")\n",
    "\n",
    "answers = [x['answer'] for x in dataset['test']]\n",
    "questions = [x['question'] for x in dataset['test']]\n",
    "choices_list = [x['choices'] for x in dataset['test']]\n",
    "\n",
    "prompts = [convert_wmdp_data_to_prompt(question, choices, prompt_format=None) for question, choices in zip(questions, choices_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters for automation process\n",
    "question_ids_correct = np.genfromtxt(\"../data/wmdp-bio_gemma_2b_it_correct.csv\")\n",
    "topk_per_prompt = 20\n",
    "\n",
    "unlearning_dataset = ['wmdp-bio']\n",
    "side_effect_dataset_names =  ['high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging', 'college_biology']\n",
    "all_dataset_names = ['loss_added', 'wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging', 'college_biology']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First get the TopK features by attribution per prompt and find the features that modify the probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_per_prompt = {}\n",
    "\n",
    "known_good_features = []\n",
    "\n",
    "for j, question_id in enumerate(question_ids_correct):\n",
    "\n",
    "    question_id = int(question_id)\n",
    "\n",
    "    print(\"Question #\", question_id, j+1, \"/172\")\n",
    "    \n",
    "    prompt = prompts[question_id]\n",
    "    choices = choices_list[question_id]\n",
    "    answer = answers[question_id]\n",
    "    question = questions[question_id]\n",
    "\n",
    "    topk_features_unique, feature_attributions, topk_features, all_feature_activations, logit_diff_grad, topk_feature_attributions = find_topk_features_given_prompt(model,\n",
    "                                                           prompt,\n",
    "                                                           question,\n",
    "                                                           choices,\n",
    "                                                           answer,\n",
    "                                                           sae,\n",
    "                                                           hook_point='blocks.9.hook_resid_pre')\n",
    "\n",
    "    intervention_results, feature_ids_to_probs, good_features = test_topk_features(model,\n",
    "                                                                                   sae,\n",
    "                                                                                   question_id,\n",
    "                                                                                   topk_features_unique[:topk_per_prompt],\n",
    "                                                                                   known_good_features=known_good_features,\n",
    "                                                                                   multiplier=30)\n",
    "\n",
    "    feature_per_prompt[question_id] = good_features\n",
    "    \n",
    "    known_good_features = list(set([item for sublist in feature_per_prompt.values() for item in sublist]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate side-effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "\n",
    "main_ablate_params = {\n",
    "                      'multiplier': 20,\n",
    "                      'intervention_method': 'clamp_feature_activation',\n",
    "                     }\n",
    "\n",
    "\n",
    "sweep = {\n",
    "         'features_to_ablate': known_good_features,\n",
    "        }\n",
    "\n",
    "metric_params = {'wmdp-bio': \n",
    "                 {\n",
    "                       'target_metric': 'correct',\n",
    "                       'permutations': None,\n",
    "                   }\n",
    "                 }\n",
    "\n",
    "dataset_names = all_dataset_names[2:]\n",
    "\n",
    "n_batch_loss_added = 10\n",
    "\n",
    "metrics_list = calculate_metrics_side_effects(model,\n",
    "                                      sae,\n",
    "                                      main_ablate_params,\n",
    "                                      sweep,\n",
    "                                      dataset_names=dataset_names,\n",
    "                                      metric_params=metric_params,\n",
    "                                      n_batch_loss_added=n_batch_loss_added,)\n",
    "                                      # activation_store=activation_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ids_zero_side_effect = [x['ablate_params']['features_to_ablate'] for x in metrics_list]\n",
    "np.array(feature_ids_zero_side_effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then sort by loss added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_store = ActivationStoreAnalysis(sae.cfg, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "\n",
    "main_ablate_params = {\n",
    "                      'multiplier': 20,\n",
    "                      'intervention_method': 'clamp_feature_activation',\n",
    "                     }\n",
    "\n",
    "\n",
    "sweep = {\n",
    "         'features_to_ablate': feature_ids_zero_side_effect,\n",
    "        }\n",
    "\n",
    "metric_params = {'wmdp-bio': \n",
    "                 {\n",
    "                       'target_metric': 'correct',\n",
    "                       'permutations': None,\n",
    "                   }\n",
    "                 }\n",
    "\n",
    "dataset_names = all_dataset_names[:2]\n",
    "\n",
    "n_batch_loss_added = 10\n",
    "\n",
    "metrics_list_zero_side_effect = calculate_metrics_list(model,\n",
    "                                      sae,\n",
    "                                      main_ablate_params,\n",
    "                                      sweep,\n",
    "                                      dataset_names=dataset_names,\n",
    "                                      metric_params=metric_params,\n",
    "                                      n_batch_loss_added=n_batch_loss_added,\n",
    "                                      activation_store=activation_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zero_side_effect = create_df_from_metrics(metrics_list_zero_side_effect)\n",
    "isorted = df_zero_side_effect.query(\"`wmdp-bio` < 1\").sort_values(\"loss_added\").index.values\n",
    "feature_ids_zero_side_effect_sorted = np.array(feature_ids_zero_side_effect)[isorted]\n",
    "feature_ids_zero_side_effect_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now progressively add features sorted by loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "\n",
    "main_ablate_params = {\n",
    "                      'multiplier': 20,\n",
    "                      'intervention_method': 'clamp_feature_activation',\n",
    "                     }\n",
    "\n",
    "\n",
    "sweep = {\n",
    "         'features_to_ablate': [feature_ids_zero_side_effect_sorted[:i+1] for i in range(25, 36)],\n",
    "         'multiplier': [15, 20, 25],\n",
    "        }\n",
    "\n",
    "metric_params = {'wmdp-bio': \n",
    "                 {\n",
    "                       'target_metric': 'correct',\n",
    "                       'permutations': None,\n",
    "                   }\n",
    "                 }\n",
    "\n",
    "dataset_names = all_dataset_names\n",
    "\n",
    "n_batch_loss_added = 20\n",
    "\n",
    "metrics_list_best_sorted = calculate_metrics_list(model,\n",
    "                                      sae,\n",
    "                                      main_ablate_params,\n",
    "                                      sweep,\n",
    "                                      dataset_names=dataset_names,\n",
    "                                      metric_params=metric_params,\n",
    "                                      n_batch_loss_added=n_batch_loss_added,\n",
    "                                      activation_store=activation_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
