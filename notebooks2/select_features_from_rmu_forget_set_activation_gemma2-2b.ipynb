{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f450a5b7f70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "\n",
    "from sae.sparse_autoencoder import load_saved_sae\n",
    "from sae.metrics import model_store_from_sae\n",
    "from unlearning.metrics import convert_wmdp_data_to_prompt, calculate_metrics_side_effects, create_df_from_metrics, calculate_metrics_list\n",
    "from unlearning.tool import UnlearningConfig, SAEUnlearningTool, MCQ_ActivationStoreAnalysis\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "from datasets import load_dataset\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "from dataclasses import dataclass\n",
    "import wandb\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import gc\n",
    "import os\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from unlearning.intervention import anthropic_remove_resid_SAE_features, remove_resid_SAE_features, anthropic_clamp_resid_SAE_features\n",
    "from unlearning.jump_relu import load_gemma2_2b_sae\n",
    "from unlearning.metrics import calculate_MCQ_metrics\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3691e3fd96f6420ea8718a3912709c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e669b4685d4341acbfa0851f0fb7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:  49%|####9     | 2.46G/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ChunkedEncodingError",
     "evalue": "('Connection broken: IncompleteRead(158593496 bytes read, 2365278664 more expected)', IncompleteRead(158593496 bytes read, 2365278664 more expected))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/urllib3/response.py:712\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 712\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/urllib3/response.py:833\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    824\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce_content_length\n\u001b[1;32m    825\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[38;5;66;03m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[1;32m    832\u001b[0m             \u001b[38;5;66;03m# Content-Length are caught.\u001b[39;00m\n\u001b[0;32m--> 833\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_bytes_read, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "\u001b[0;31mIncompleteRead\u001b[0m: IncompleteRead(158593496 bytes read, 2365278664 more expected)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/urllib3/response.py:934\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 934\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/urllib3/response.py:905\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m<\u001b[39m amt \u001b[38;5;129;01mand\u001b[39;00m data:\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;66;03m# TODO make sure to initially read enough data to get past the headers\u001b[39;00m\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# For example, the GZ file header takes 10 bytes, we don't want to read\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# it one byte at a time\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m     decoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(data, decode_content, flush_decoder)\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/urllib3/response.py:811\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    809\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 811\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m    812\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_read(amt) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/urllib3/response.py:729\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (HTTPException, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;66;03m# This includes IncompleteRead.\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProtocolError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection broken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;66;03m# If no exception is thrown, we should avoid cleaning up\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;66;03m# unnecessarily.\u001b[39;00m\n",
      "\u001b[0;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(158593496 bytes read, 2365278664 more expected)', IncompleteRead(158593496 bytes read, 2365278664 more expected))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/gemma-2-2b-it\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3671\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3668\u001b[0m \u001b[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001b[39;00m\n\u001b[1;32m   3669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sharded:\n\u001b[1;32m   3670\u001b[0m     \u001b[38;5;66;03m# resolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001b[39;00m\n\u001b[0;32m-> 3671\u001b[0m     resolved_archive_file, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_checkpoint_shard_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3680\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3682\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3683\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3684\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3686\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3687\u001b[0m     is_safetensors_available()\n\u001b[1;32m   3688\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resolved_archive_file, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m   3689\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m resolved_archive_file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3690\u001b[0m ):\n\u001b[1;32m   3691\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m safe_open(resolved_archive_file, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:1079\u001b[0m, in \u001b[0;36mget_checkpoint_shard_files\u001b[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m shard_filename \u001b[38;5;129;01min\u001b[39;00m tqdm(shard_filenames, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading shards\u001b[39m\u001b[38;5;124m\"\u001b[39m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[1;32m   1077\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1078\u001b[0m         \u001b[38;5;66;03m# Load from URL\u001b[39;00m\n\u001b[0;32m-> 1079\u001b[0m         cached_filename \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshard_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_commit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[38;5;66;03m# we don't have to catch them here.\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError:\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/transformers/utils/hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    399\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m   1203\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1218\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1219\u001b[0m     )\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1367\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1365\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1367\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1377\u001b[0m     _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1884\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1881\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1882\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1884\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1891\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1893\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1894\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:539\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    537\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 539\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[1;32m    541\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/unlearning/.venv/lib/python3.10/site-packages/requests/models.py:822\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 822\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContentDecodingError(e)\n",
      "\u001b[0;31mChunkedEncodingError\u001b[0m: ('Connection broken: IncompleteRead(158593496 bytes read, 2365278664 more expected)', IncompleteRead(158593496 bytes read, 2365278664 more expected))"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_name = \"google/gemma-2-2b-it\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\").to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "model.tokenizer = tokenizer\n",
    "model.cfg = SimpleNamespace()\n",
    "model.cfg.model_name = 'gemma-2-2b-it'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found SAE with l0=59 at path google/gemma-scope-2b-pt-res/layer_3/width_16k/average_l0_59/params.npz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "JumpReLUSAE()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae = load_gemma2_2b_sae(layer=3)\n",
    "sae.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(forget_corpora, retain_corpora, min_len=50, max_len=2000, batch_size=4):\n",
    "    def get_dataset(name):\n",
    "        data = []\n",
    "        if name == \"wikitext\":\n",
    "            raw_data = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "            for x in raw_data:\n",
    "                if len(x['text']) > min_len:\n",
    "                    data.append(str(x['text']))\n",
    "        else:\n",
    "            for line in open(f\"../wmdp/data/{name}.jsonl\", \"r\"):\n",
    "                if \"bio-forget-corpus\" in name:\n",
    "                    raw_text = json.loads(line)['text']\n",
    "                else:\n",
    "                    raw_text = line\n",
    "                if len(raw_text) > min_len:\n",
    "                    data.append(str(raw_text))\n",
    "        return data\n",
    "\n",
    "    return get_dataset(forget_corpora), get_dataset(retain_corpora)\n",
    "\n",
    "forget_dataset, retain_dataset = get_data('bio-forget-corpus', 'wikitext')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24432 16027\n",
      "1962 859\n"
     ]
    }
   ],
   "source": [
    "print(len(forget_dataset), len(forget_dataset[0]))\n",
    "print(len(retain_dataset), len(retain_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(model, dataset, seq_len=1024, max_batch=32):\n",
    "    # just for quick testing on smaller tokens \n",
    "    # dataset = dataset[:max_batch]\n",
    "    full_text = model.tokenizer.eos_token.join(dataset)\n",
    "    \n",
    "    # divide into chunks to speed up tokenization\n",
    "    num_chunks = 20\n",
    "    chunk_length = (len(full_text) - 1) // num_chunks + 1\n",
    "    chunks = [full_text[i * chunk_length:(i + 1) * chunk_length] for i in range(num_chunks)]\n",
    "    tokens = model.tokenizer(chunks, return_tensors=\"pt\", padding=True)[\"input_ids\"].flatten()\n",
    "    \n",
    "    # remove pad token\n",
    "    tokens = tokens[tokens != model.tokenizer.pad_token_id]\n",
    "    num_tokens = len(tokens)\n",
    "    num_batches = num_tokens // seq_len\n",
    "    \n",
    "    # drop last batch if not full\n",
    "    tokens = tokens[:num_batches * seq_len]\n",
    "    tokens = einops.rearrange(\n",
    "        tokens, \"(batch seq) -> batch seq\", batch=num_batches, seq=seq_len\n",
    "    )\n",
    "    # change first token to bos\n",
    "    tokens[:, 0] = model.config.bos_token_id\n",
    "    return tokens.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([153108, 1024]) torch.Size([275, 1024])\n"
     ]
    }
   ],
   "source": [
    "forget_tokens = tokenize_dataset(model, forget_dataset)\n",
    "retain_tokens = tokenize_dataset(model, retain_dataset)\n",
    "\n",
    "print(forget_tokens.shape, retain_tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_residual_activations(model, target_layer, inputs):\n",
    "    target_act = None\n",
    "    def gather_target_act_hook(mod, inputs, outputs):\n",
    "        nonlocal target_act # make sure we can modify the target_act from the outer scope\n",
    "        target_act = outputs[0]\n",
    "        return outputs\n",
    "    handle = model.model.layers[target_layer].register_forward_hook(gather_target_act_hook)\n",
    "    _ = model.forward(inputs)\n",
    "    handle.remove()\n",
    "    return target_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_feature_activation(sae, tokens, batch_size=4):\n",
    "    mean_acts = []\n",
    "    layer = int(sae.cfg.hook_point.split('.')[1])\n",
    "    for i in tqdm(range(0, tokens.shape[0], batch_size)):\n",
    "        with torch.no_grad():\n",
    "            # _, cache = model.run_with_cache(tokens[i:i + batch_size], names_filter=sae.cfg.hook_name)\n",
    "            # resid: Float[Tensor, 'batch pos d_model'] = cache[sae.cfg.hook_name]\n",
    "            resid: Float[Tensor, 'batch pos d_model'] = gather_residual_activations(model, layer, tokens[i:i + batch_size])\n",
    "            resid = resid.to(torch.float)\n",
    "            \n",
    "            act: Float[Tensor, 'batch pos d_sae'] = sae.encode(resid)\n",
    "            current_mean_act = einops.reduce(act, 'batch pos d_sae -> d_sae', 'mean')\n",
    "        \n",
    "        mean_acts.append(current_mean_act)\n",
    "        \n",
    "        # Free up memory\n",
    "        del resid, act\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    mean_acts = torch.stack(mean_acts)\n",
    "    return mean_acts.to(torch.float16).mean(dim=0).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [03:57<00:00,  1.08it/s]\n",
      "100%|██████████| 35/35 [00:31<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# shuffle forget_tokens \n",
    "shuffled_forget_tokens = forget_tokens[torch.randperm(forget_tokens.shape[0])]\n",
    "\n",
    "mean_feature_activation_forget = get_mean_feature_activation(sae, shuffled_forget_tokens[:2048], batch_size=8)\n",
    "mean_feature_activation_retain = get_mean_feature_activation(sae, retain_tokens, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_comparison(forget, retain, good_feature_lst=[]):\n",
    "    # add color to selected features\n",
    "    color = np.array(['Normal'] * len(forget))\n",
    "    color[good_feature_lst] = 'Selected from MCQ'\n",
    "    \n",
    "    # main plot\n",
    "    fig = px.scatter(x=forget, y=retain, labels={'x': 'Forget', 'y': 'Retain'}, hover_data=[np.arange(len(forget))], color=color)\n",
    "    \n",
    "    # add a diagonal line\n",
    "    max_val = min(max(forget), max(retain))\n",
    "    fig.add_shape(\n",
    "        type=\"line\", line=dict(dash=\"dash\"),\n",
    "        x0=0, y0=0, x1=max_val, y1=max_val\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "    \n",
    "# plot_comparison(mean_feature_activation_forget, mean_feature_activation_retain)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8802  1676 10793  8803  1082  8131  9870   570 10387  6798  6396 14059\n",
      "  1960 10929  8715 12095 11695  9971  1312 16323]\n"
     ]
    }
   ],
   "source": [
    "# criteria for selecting features: retain score < 0.01 and then sort by forget score\n",
    "high_retain_score_features = np.where(mean_feature_activation_retain >= 0.01)[0]\n",
    "modified_forget_score = mean_feature_activation_forget.copy()\n",
    "modified_forget_score[high_retain_score_features] = 0\n",
    "top_features = modified_forget_score.argsort()[::-1]\n",
    "print(top_features[:20])\n",
    "\n",
    "n_non_zero_features = np.count_nonzero(modified_forget_score)\n",
    "top_features_non_zero = top_features[:n_non_zero_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://neuronpedia.org/quick-list/?name=temporary_list&features=%5B%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%228802%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%221676%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%2210793%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%228803%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%221082%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%228131%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%229870%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%22570%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%2210387%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%226798%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%226396%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%2214059%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%221960%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%2210929%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%228715%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%2212095%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%2211695%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%229971%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%221312%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%223-gemmascope-res-16k%22%2C%20%22index%22%3A%20%2216323%22%7D%5D'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n",
    "\n",
    "get_neuronpedia_quick_list(top_features[:20], layer=3, model='gemma-2-2b', dataset='gemmascope-res-16k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:18<00:00, 11.27it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.14it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.67it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 20, multiplier: 0\n",
      "\t\twmdp-bio: 0.6355066895484924\n",
      "\t\thigh_school_us_history: 0.7401961088180542\n",
      "\t\thuman_aging: 0.6322870254516602\n",
      "\t\tcollege_bio: 0.7083333134651184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.20it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.14it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.74it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 20, multiplier: 10\n",
      "\t\twmdp-bio: 0.5514532923698425\n",
      "\t\thigh_school_us_history: 0.75\n",
      "\t\thuman_aging: 0.6278027296066284\n",
      "\t\tcollege_bio: 0.6527777910232544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.21it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.14it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.71it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 20, multiplier: 20\n",
      "\t\twmdp-bio: 0.5090337991714478\n",
      "\t\thigh_school_us_history: 0.75\n",
      "\t\thuman_aging: 0.6098654866218567\n",
      "\t\tcollege_bio: 0.5902777910232544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.20it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.74it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 20, multiplier: 40\n",
      "\t\twmdp-bio: 0.431264728307724\n",
      "\t\thigh_school_us_history: 0.7696078419685364\n",
      "\t\thuman_aging: 0.5156950950622559\n",
      "\t\tcollege_bio: 0.4791666567325592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.18it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.72it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 40, multiplier: 0\n",
      "\t\twmdp-bio: 0.6355066895484924\n",
      "\t\thigh_school_us_history: 0.7401961088180542\n",
      "\t\thuman_aging: 0.6322870254516602\n",
      "\t\tcollege_bio: 0.7083333134651184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.16it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.70it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 40, multiplier: 10\n",
      "\t\twmdp-bio: 0.5318146347999573\n",
      "\t\thigh_school_us_history: 0.7598039507865906\n",
      "\t\thuman_aging: 0.6367713212966919\n",
      "\t\tcollege_bio: 0.6666666865348816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.18it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.66it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 40, multiplier: 20\n",
      "\t\twmdp-bio: 0.46739986538887024\n",
      "\t\thigh_school_us_history: 0.7598039507865906\n",
      "\t\thuman_aging: 0.573991060256958\n",
      "\t\tcollege_bio: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.16it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.70it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 40, multiplier: 40\n",
      "\t\twmdp-bio: 0.3967007100582123\n",
      "\t\thigh_school_us_history: 0.7009804248809814\n",
      "\t\thuman_aging: 0.4708520472049713\n",
      "\t\tcollege_bio: 0.4861111044883728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.15it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.69it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 60, multiplier: 0\n",
      "\t\twmdp-bio: 0.6355066895484924\n",
      "\t\thigh_school_us_history: 0.7401961088180542\n",
      "\t\thuman_aging: 0.6322870254516602\n",
      "\t\tcollege_bio: 0.7083333134651184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.15it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.69it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 60, multiplier: 10\n",
      "\t\twmdp-bio: 0.5106048583984375\n",
      "\t\thigh_school_us_history: 0.7303921580314636\n",
      "\t\thuman_aging: 0.6278027296066284\n",
      "\t\tcollege_bio: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.14it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.12it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.60it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 60, multiplier: 20\n",
      "\t\twmdp-bio: 0.3943440914154053\n",
      "\t\thigh_school_us_history: 0.6568627953529358\n",
      "\t\thuman_aging: 0.5874439477920532\n",
      "\t\tcollege_bio: 0.4166666567325592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.15it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.68it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 60, multiplier: 40\n",
      "\t\twmdp-bio: 0.310290664434433\n",
      "\t\thigh_school_us_history: 0.44117647409439087\n",
      "\t\thuman_aging: 0.5022422075271606\n",
      "\t\tcollege_bio: 0.3541666567325592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.17it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.12it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.60it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 80, multiplier: 0\n",
      "\t\twmdp-bio: 0.6355066895484924\n",
      "\t\thigh_school_us_history: 0.7401961088180542\n",
      "\t\thuman_aging: 0.6322870254516602\n",
      "\t\tcollege_bio: 0.7083333134651184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.17it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.63it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 80, multiplier: 10\n",
      "\t\twmdp-bio: 0.5003927946090698\n",
      "\t\thigh_school_us_history: 0.7303921580314636\n",
      "\t\thuman_aging: 0.6098654866218567\n",
      "\t\tcollege_bio: 0.6458333134651184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.17it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.69it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 80, multiplier: 20\n",
      "\t\twmdp-bio: 0.38570305705070496\n",
      "\t\thigh_school_us_history: 0.6568627953529358\n",
      "\t\thuman_aging: 0.5515695214271545\n",
      "\t\tcollege_bio: 0.3819444477558136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [00:19<00:00, 11.15it/s]\n",
      "100%|██████████| 34/34 [00:08<00:00,  4.13it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 16.70it/s]\n",
      "100%|██████████| 24/24 [00:02<00:00, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 80, multiplier: 40\n",
      "\t\twmdp-bio: 0.2867242693901062\n",
      "\t\thigh_school_us_history: 0.3970588445663452\n",
      "\t\thuman_aging: 0.47533634305000305\n",
      "\t\tcollege_bio: 0.3402777910232544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "from functools import partial\n",
    "\n",
    "def scale_feature_hook(mod, inputs, outputs, sae, features_to_ablate, multiplier):\n",
    "    resid = outputs[0].to(torch.float)\n",
    "    reconstruction = sae(resid)\n",
    "    feature_activations = sae.encode(resid)\n",
    "    error = resid - reconstruction\n",
    "    \n",
    "    feature_activations[:, :, features_to_ablate] -= multiplier * feature_activations[:, :, features_to_ablate]\n",
    "    modified_reconstruction = feature_activations @ sae.W_dec + sae.b_dec\n",
    "    \n",
    "    resid = error + modified_reconstruction\n",
    "    return (resid.to(torch.bfloat16), None)\n",
    "\n",
    "@contextmanager\n",
    "def scaling_intervention(model, layer, sae, features_to_ablate, multiplier):\n",
    "    \"\"\"intervene on resid post at given layer\"\"\"\n",
    "    handle = model.model.layers[layer].register_forward_hook(\n",
    "        partial(scale_feature_hook, sae=sae, features_to_ablate=features_to_ablate, multiplier=multiplier)\n",
    "    )\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        handle.remove()\n",
    "\n",
    "\n",
    "\n",
    "layer = 3\n",
    "features_to_ablate = list(top_features[:80])\n",
    "multiplier = 20\n",
    "\n",
    "for n_features in [20, 40, 60, 80]:\n",
    "    for multiplier in [0, 10, 20, 40]:\n",
    "        features_to_ablate = list(top_features[:n_features])\n",
    "        with scaling_intervention(model, layer, sae, features_to_ablate, multiplier):\n",
    "            intervened_metrics = calculate_MCQ_metrics(model)\n",
    "            intervened_history_metrics = calculate_MCQ_metrics(model, dataset_name='high_school_us_history')\n",
    "            interved_human_aging_metrics = calculate_MCQ_metrics(model, dataset_name='human_aging')\n",
    "            intervened_college_bio_metrics = calculate_MCQ_metrics(model, dataset_name='college_biology')\n",
    "            \n",
    "            print(f\"n_features: {n_features}, multiplier: {multiplier}\")\n",
    "            print(f\"\\t\\twmdp-bio: {intervened_metrics['mean_correct']}\")\n",
    "            print(f\"\\t\\thigh_school_us_history: {intervened_history_metrics['mean_correct']}\")\n",
    "            print(f\"\\t\\thuman_aging: {interved_human_aging_metrics['mean_correct']}\")\n",
    "            print(f\"\\t\\tcollege_bio: {intervened_college_bio_metrics['mean_correct']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('./unlearning_output/gemma2-2b-it_layer3_forget_set_features.txt', top_features, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5483111143112183\n",
      "0.7401961088180542\n"
     ]
    }
   ],
   "source": [
    "print(intervened_metrics['mean_correct'])\n",
    "print(intervened_history_metrics['mean_correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5200314521789551\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "print(intervened_metrics['mean_correct'])\n",
    "print(intervened_history_metrics['mean_correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42262372374534607\n",
      "0.7450980544090271\n"
     ]
    }
   ],
   "source": [
    "print(intervened_metrics['mean_correct'])\n",
    "print(intervened_history_metrics['mean_correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35113903880119324\n",
      "0.6960784792900085\n"
     ]
    }
   ],
   "source": [
    "print(intervened_metrics['mean_correct'])\n",
    "print(intervened_history_metrics['mean_correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_correct': 0.42262372374534607,\n",
       " 'total_correct': 538,\n",
       " 'is_correct': array([0., 1., 0., ..., 1., 1., 1.], dtype=float32),\n",
       " 'output_probs': array([[0.02899 , 0.62    , 0.03497 , 0.1776  ],\n",
       "        [0.05374 , 0.0393  , 0.02104 , 0.373   ],\n",
       "        [0.01678 , 0.02025 , 0.01392 , 0.917   ],\n",
       "        ...,\n",
       "        [0.0923  , 0.0923  , 0.1836  , 0.02333 ],\n",
       "        [0.0511  , 0.1151  , 0.294   , 0.06555 ],\n",
       "        [0.00775 , 0.0136  , 0.7427  , 0.008255]], dtype=float16),\n",
       " 'actual_answers': array([0, 3, 2, ..., 2, 2, 2]),\n",
       " 'predicted_answers': array([1, 3, 3, ..., 2, 2, 2]),\n",
       " 'predicted_probs': array([0.62  , 0.373 , 0.917 , ..., 0.1836, 0.294 , 0.7427], dtype=float16),\n",
       " 'predicted_probs_of_correct_answers': array([0.02899, 0.373  , 0.01392, ..., 0.1836 , 0.294  , 0.7427 ],\n",
       "       dtype=float16),\n",
       " 'mean_predicted_prob_of_correct_answers': 0.3037109375,\n",
       " 'mean_predicted_probs': 0.56787109375,\n",
       " 'value_counts': {0: 178, 1: 355, 2: 372, 3: 368},\n",
       " 'sum_abcd': array([0.862 , 0.487 , 0.968 , ..., 0.3916, 0.526 , 0.7725], dtype=float16)}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervened_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:06<00:00,  5.11it/s]\n"
     ]
    }
   ],
   "source": [
    "history_metrics = calculate_MCQ_metrics(model, dataset_name='high_school_us_history')\n",
    "metrics = calculate_MCQ_metrics(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
