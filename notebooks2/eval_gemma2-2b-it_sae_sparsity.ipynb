{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "from unlearning.tool import get_hf_model\n",
    "from unlearning.feature_activation import get_forget_retain_data, tokenize_dataset, get_feature_activation_sparsity, get_top_features\n",
    "from unlearning.jump_relu import load_gemma2_2b_sae\n",
    "from unlearning.intervention import scaling_intervention\n",
    "from unlearning.metrics import calculate_MCQ_metrics, get_loss_added_hf, create_df_from_metrics, generate_ablate_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found SAE with l0=84 at path google/gemma-scope-2b-pt-res/layer_13/width_16k/average_l0_84/params.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constantSetting center_unembed=False instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a36f0b84de84bac97282af5660290eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2-2b-it into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "layer = 13\n",
    "sae = load_gemma2_2b_sae(layer=layer)\n",
    "\n",
    "\n",
    "model = HookedTransformer.from_pretrained('google/gemma-2-2b-it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae.activation_store import ActivationsStore\n",
    "\n",
    "sae.cfg.dataset = \"Skylion007/openwebtext\"\n",
    "sae.cfg.n_batches_in_store_buffer = 8\n",
    "\n",
    "activation_store = ActivationsStore(sae.cfg, model, create_dataloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "ret = get_loss_added_hf(model, activation_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_features = np.loadtxt(f'../data/top_features/gemma-2-2b-it-sparsity/layer3.txt', dtype=int)\n",
    "# top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "forget_sparsity = np.loadtxt(f'../data/top_features/gemma-2-2b-it-sparsity/layer{layer}_mean_feature_activation_forget.txt', dtype=float)\n",
    "retain_sparsity = np.loadtxt(f'../data/top_features/gemma-2-2b-it-sparsity/layer{layer}_mean_feature_activation_retain.txt', dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8228  2807  3285  4618 11585 11761  5469  2644  1894 15250  9404 12023\n",
      "  2570  4470  3372  1287 13018  1861  2292 15030]\n"
     ]
    }
   ],
   "source": [
    "from unlearning.feature_activation import get_top_features\n",
    "top_features = get_top_features(forget_sparsity, retain_sparsity, retain_threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12994"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset_names = ['loss_added', 'wmdp-bio', 'high_school_us_history', 'college_computer_science', 'high_school_geography', 'human_aging', 'college_biology']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8228  2807  3285  4618 11585 11761  5469  2644  1894 15250  9404 12023\n",
      "  2570  4470  3372  1287 13018  1861  2292 15030]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:27<00:00,  3.16it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.16it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.15it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.17it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.16it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.14it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.16it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.13it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.12it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.11it/s]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.13it/s]]\n",
      "100%|██████████| 87/87 [00:28<00:00,  3.10it/s]]\n",
      "100%|██████████| 87/87 [00:28<00:00,  3.10it/s]]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.12it/s]]\n",
      "100%|██████████| 87/87 [00:27<00:00,  3.14it/s]]\n",
      "100%|██████████| 15/15 [49:51<00:00, 199.43s/it]\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "from unlearning.metrics import calculate_metrics_list\n",
    "\n",
    "\n",
    "for retain_threshold in [0.01]: # [0.001, 0.01]\n",
    "    top_features_custom = get_top_features(forget_sparsity, retain_sparsity, retain_threshold=retain_threshold)\n",
    "\n",
    "    main_ablate_params = {\n",
    "                        'intervention_method': 'clamp_feature_activation',\n",
    "                        }\n",
    "\n",
    "\n",
    "    sweep = {\n",
    "            'features_to_ablate': [np.array(top_features_custom[:10]), np.array(top_features_custom[:20]), np.array(top_features_custom[:50])],\n",
    "            'multiplier': [1, 5, 10, 50, 100],\n",
    "            \n",
    "            }\n",
    "\n",
    "\n",
    "    metrics_list = calculate_metrics_list(\n",
    "        model,\n",
    "        sae,\n",
    "        main_ablate_params,\n",
    "        sweep,\n",
    "        all_dataset_names,\n",
    "        n_batch_loss_added=50,\n",
    "        activation_store=activation_store,\n",
    "        target_metric='correct',\n",
    "        save_metrics=True,\n",
    "        notes=f'_sparsity_thres{retain_threshold}'\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_added</th>\n",
       "      <th>wmdp-bio</th>\n",
       "      <th>high_school_us_history</th>\n",
       "      <th>college_computer_science</th>\n",
       "      <th>high_school_geography</th>\n",
       "      <th>human_aging</th>\n",
       "      <th>college_biology</th>\n",
       "      <th>wmdp-bio_prob</th>\n",
       "      <th>high_school_us_history_prob</th>\n",
       "      <th>college_computer_science_prob</th>\n",
       "      <th>high_school_geography_prob</th>\n",
       "      <th>human_aging_prob</th>\n",
       "      <th>college_biology_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.904785</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.874023</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000515</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833008</td>\n",
       "      <td>0.905273</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.891602</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.919434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.834473</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.892090</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.919922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.910645</td>\n",
       "      <td>0.892090</td>\n",
       "      <td>0.874512</td>\n",
       "      <td>0.920898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000647</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839844</td>\n",
       "      <td>0.906738</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>0.873535</td>\n",
       "      <td>0.923828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.975096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.844238</td>\n",
       "      <td>0.909180</td>\n",
       "      <td>0.913574</td>\n",
       "      <td>0.897461</td>\n",
       "      <td>0.873047</td>\n",
       "      <td>0.926270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831543</td>\n",
       "      <td>0.905273</td>\n",
       "      <td>0.908203</td>\n",
       "      <td>0.892090</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.920410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.000994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832520</td>\n",
       "      <td>0.905273</td>\n",
       "      <td>0.907227</td>\n",
       "      <td>0.892578</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.921387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.000946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833008</td>\n",
       "      <td>0.905273</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.892578</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.922363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.905273</td>\n",
       "      <td>0.875977</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>0.874512</td>\n",
       "      <td>0.924805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.013745</td>\n",
       "      <td>0.957854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.813477</td>\n",
       "      <td>0.908691</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.895508</td>\n",
       "      <td>0.874512</td>\n",
       "      <td>0.922852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.000323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827637</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>0.907227</td>\n",
       "      <td>0.888184</td>\n",
       "      <td>0.872559</td>\n",
       "      <td>0.919434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827148</td>\n",
       "      <td>0.899414</td>\n",
       "      <td>0.906738</td>\n",
       "      <td>0.887695</td>\n",
       "      <td>0.872070</td>\n",
       "      <td>0.919922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.998084</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.826172</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.886719</td>\n",
       "      <td>0.871094</td>\n",
       "      <td>0.920410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.027516</td>\n",
       "      <td>0.984674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.814453</td>\n",
       "      <td>0.892578</td>\n",
       "      <td>0.879395</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.866699</td>\n",
       "      <td>0.912598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.094693</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.990566</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.787598</td>\n",
       "      <td>0.893066</td>\n",
       "      <td>0.912109</td>\n",
       "      <td>0.888184</td>\n",
       "      <td>0.850098</td>\n",
       "      <td>0.889160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loss_added  wmdp-bio  high_school_us_history  college_computer_science  \\\n",
       "0     0.000000  1.000000                1.000000                  1.000000   \n",
       "1    -0.000515  1.000000                1.000000                  1.000000   \n",
       "2    -0.000714  1.000000                1.000000                  1.000000   \n",
       "3    -0.000906  1.000000                1.000000                  1.000000   \n",
       "4    -0.000647  0.994253                1.000000                  1.000000   \n",
       "5     0.002941  0.975096                1.000000                  1.000000   \n",
       "6    -0.000909  1.000000                1.000000                  1.000000   \n",
       "7    -0.000994  1.000000                1.000000                  1.000000   \n",
       "8    -0.000946  1.000000                1.000000                  1.000000   \n",
       "9     0.002775  0.994253                1.000000                  1.000000   \n",
       "10    0.013745  0.957854                1.000000                  0.888889   \n",
       "11   -0.000323  1.000000                1.000000                  1.000000   \n",
       "12    0.000327  1.000000                1.000000                  1.000000   \n",
       "13    0.001727  0.998084                1.000000                  1.000000   \n",
       "14    0.027516  0.984674                1.000000                  1.000000   \n",
       "15    0.094693  0.919540                0.990566                  0.888889   \n",
       "\n",
       "    high_school_geography  human_aging  college_biology  wmdp-bio_prob  \\\n",
       "0                1.000000     1.000000         1.000000       0.828125   \n",
       "1                1.000000     1.000000         1.000000       0.833008   \n",
       "2                1.000000     1.000000         1.000000       0.834473   \n",
       "3                1.000000     1.000000         1.000000       0.835938   \n",
       "4                1.000000     0.987654         1.000000       0.839844   \n",
       "5                1.000000     0.987654         0.986301       0.844238   \n",
       "6                1.000000     1.000000         1.000000       0.831543   \n",
       "7                1.000000     1.000000         1.000000       0.832520   \n",
       "8                1.000000     1.000000         1.000000       0.833008   \n",
       "9                1.000000     1.000000         1.000000       0.822266   \n",
       "10               1.000000     0.987654         0.986301       0.813477   \n",
       "11               1.000000     1.000000         1.000000       0.827637   \n",
       "12               1.000000     1.000000         1.000000       0.827148   \n",
       "13               1.000000     1.000000         1.000000       0.826172   \n",
       "14               0.990385     0.987654         1.000000       0.814453   \n",
       "15               0.980769     0.938272         0.945205       0.787598   \n",
       "\n",
       "    high_school_us_history_prob  college_computer_science_prob  \\\n",
       "0                      0.904785                       0.909180   \n",
       "1                      0.905273                       0.910156   \n",
       "2                      0.905762                       0.910156   \n",
       "3                      0.905762                       0.910645   \n",
       "4                      0.906738                       0.912598   \n",
       "5                      0.909180                       0.913574   \n",
       "6                      0.905273                       0.908203   \n",
       "7                      0.905273                       0.907227   \n",
       "8                      0.905273                       0.905762   \n",
       "9                      0.905273                       0.875977   \n",
       "10                     0.908691                       0.905762   \n",
       "11                     0.899902                       0.907227   \n",
       "12                     0.899414                       0.906738   \n",
       "13                     0.898438                       0.905762   \n",
       "14                     0.892578                       0.879395   \n",
       "15                     0.893066                       0.912109   \n",
       "\n",
       "    high_school_geography_prob  human_aging_prob  college_biology_prob  \n",
       "0                     0.890625          0.874023              0.917969  \n",
       "1                     0.891602          0.875000              0.919434  \n",
       "2                     0.892090          0.875000              0.919922  \n",
       "3                     0.892090          0.874512              0.920898  \n",
       "4                     0.894531          0.873535              0.923828  \n",
       "5                     0.897461          0.873047              0.926270  \n",
       "6                     0.892090          0.875488              0.920410  \n",
       "7                     0.892578          0.875488              0.921387  \n",
       "8                     0.892578          0.875000              0.922363  \n",
       "9                     0.894531          0.874512              0.924805  \n",
       "10                    0.895508          0.874512              0.922852  \n",
       "11                    0.888184          0.872559              0.919434  \n",
       "12                    0.887695          0.872070              0.919922  \n",
       "13                    0.886719          0.871094              0.920410  \n",
       "14                    0.880859          0.866699              0.912598  \n",
       "15                    0.888184          0.850098              0.889160  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_df_from_metrics(metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
